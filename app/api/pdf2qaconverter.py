import grequests
import openai
import fitz
import nltk
import os
nltk.download('punkt')
from dotenv import load_dotenv
from nltk import tokenize
import tempfile
import logging

# Load the .env file containing the OpenAI API key
# Create a .env file storing your key
load_dotenv('openai_key.env')

# Log configuration
logging.basicConfig(filename='pdf2qa.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class PDF2QAConverter:
    """
    This classs contains utility functions for the converter.
    """
    
    @staticmethod
    def get_text_data(pdf_path: str) -> str:
        """
        Function extracts the text from the PDF file.

        Args:
            pdf_path (string): Path of the PDF file saved in the temp
            directory
        
        Returns:
            str: contains the text data
        """
        logging.info('Opening the PDF file to read its contents. . .')
        with fitz.open(pdf_path) as doc:
            text = "".join(page.get_text() for page in doc)
            if text is not None:
                logging.info('Extracted the text content from the PDF file.')
            else:
                logging.info('Something went wrong with extraction. . .')
            return text

    
    @staticmethod
    def get_paragraphs(text_data: str) -> list:
        """
        Function to extract the paragraphs from the text data.

        Args:
            text_data (string): extracted text data from the PDF file
        
        Returns:
            list: paragraphs from the text data
        """

        result = tokenize.sent_tokenize(text_data)
        logging.info('Created sentence tokens from the paragraphs.')

        paragraphs = []
        str_paragraph = ""

        for i in range(len(result)):
            sentence = result[i]
            len_para = len(tokenize.word_tokenize(str_paragraph))
            logging.info('Created word tokens from the sentences.')

            logging.info('Joining the words to make up the paragraphs. . .')
            if len_para < 200:
                str_paragraph += ' ' + sentence
            elif len_para >= 200:
                paragraphs.append(str_paragraph)

                str_paragraph = ''
                str_paragraph += ' ' + sentence
            elif i == len(result) - 1:
                paragraphs.append(str_paragraph)
        
        if len(paragraphs) > 0:
            logging.info('Extracted the paragraphs')
        else:
            logging.info('Paragraphs list is empty, check the PDF file contents.')
        return paragraphs

    # Function to get the response from OpenAI's api
    @staticmethod
    def get_qna_openai(paragraphs: list) -> list:
        """
        Function to get the QnA pair as response from OpenAI.
        The requests to openai are stored in a list and then
        sent out in batches using the grequests library.

        Args:
            paragraphs (list): paragraph from the text data passed as prompt
            to the OpenAI model.
        
        Returns:
            list: QnA pair generated by OpenAI model.
        """

        # OpenAI API endpoint for completions and key
        openai_endpoint = "https://api.openai.com/v1/completions"
        openai.api_key = os.environ.get('OPENAI_API_KEY')

        # Header content to call the OpenAI endpoint
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {openai.api_key}"
        }

        requests = []   # list to store the request objects
        for index, para in enumerate(paragraphs):
            data = {
                "model": "text-davinci-003",
                "prompt":f"Generate 2 descriptive questions and answers for paragraph :{para}",
                "max_tokens":200,
                "temperature": 0.9,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0
            }
            logging.info(f'Creating a list of unsent request for paragraph, "{para}"')
            request = grequests.post(openai_endpoint, json=data, headers=headers)
            requests.append(request)
        logging.info(f'Created request {request} and stored in the list.')
        
        index = 0   # variable used to index the pargraphs
        para_qna_list = []  # list to store the paragraph, question and answer as dict

        logging.info('Sending out unsent requests in batches of size 20. . .')
        responses = grequests.map(requests, size=20)

        logging.info('Iterating through the responses. . .')
        for response in responses:
            if response is not None and response.status_code == 200:
                result = response.json()['choices'][0]['text']
                logging.info('Creating temp file to store the response. . .')
                with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:
                    logging.info('Opened the temporary file')
                    try:
                        logging.info(f'Writing the contents to the temp file. . .{result}')
                        temp_file.write(result)
                    except Exception as err:
                        logging.info(f'Something went wrong. . .{err}')

                    temp_file.flush()
                    temp_file_path = temp_file.name
                try:
                    with open(temp_file_path, 'r') as temp_file:
                        lines = temp_file.readlines()
                        logging.info('Extracting the qna from the temp file. . .')
                        pairs = PDF2QAConverter.parse_qa_pairs(lines)
                        logging.info(f'Extracted QNA pairs - {pairs}')
                except Exception as err:
                    logging.info(f'Someting went wrong. . .{err}')
                
                for q, a in pairs:
                    try:
                        para_qna_list.append({'Paragraph': paragraphs[index], 'Question': PDF2QAConverter.remove_qa_prefix(q), 'Answer': PDF2QAConverter.remove_qa_prefix(a)})
                    except Exception as err:
                        logging.info('QnA was an empty sequence, moving to the next set')
                        logging.info(err)
                index += 1
            else:
                logging.info(response)

        logging.info('Extracted the qna from the paragraphs.')
        return para_qna_list
        

    # Function to split the Question and Answer by removing prefixes before the actual Question and Answers
    @staticmethod
    def remove_qa_prefix(text: str) -> str:
        """
        Function removes any delimiters from the OpenAI response.

        Args:
            text (string): The response from OpenAI.

        Returns:
            str: Clean response.
        """
        delimiters = ['.', '-', ':']
        first_occurrence_index = min(text.find(delimiter) for delimiter in delimiters if text.find(delimiter) != -1)
        return text[first_occurrence_index + 1:].strip()

    # Function to parse Q&A pairs from lines
    @staticmethod
    def parse_qa_pairs(lines: list) -> list:
        """
        Function to extract the QnA from the OpenAI response
        stored in text file.

        Args:
            lines (list): The lines read from the text file.
        
        Returns:
            list: Extracted QnA as pairs.
        """
        pairs = []
        current_q = ''
        current_a = ''

        for line in lines:
            line = line.strip()
            if line.startswith('Q'):
                if current_q:
                    pairs.append((current_q, current_a))
                current_q = line
                current_a = ''
            elif line.startswith('A'):
                current_a += line[:] + '\n'

        if current_q:
            pairs.append((current_q, current_a))

        return pairs